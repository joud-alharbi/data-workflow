{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üè† Import the house price data set. We will keep only numerical features for the sake of simplicity\n",
    "\n",
    "üéØ Your goal will be to fit the best KNN Regressor. In particular, how many \"neighbors\" (<font color=blue>K</font> in <font color=blue>K</font>NN) should you consider to get the best predictions for your house prices ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                            \n",
       "1             60         65.0     8450            7            5       2003   \n",
       "2             20         80.0     9600            6            8       1976   \n",
       "3             60         68.0    11250            7            5       2001   \n",
       "4             70         60.0     9550            7            5       1915   \n",
       "5             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1456          60         62.0     7917            6            5       1999   \n",
       "1457          20         85.0    13175            6            6       1978   \n",
       "1458          70         66.0     9042            7            9       1941   \n",
       "1459          20         68.0     9717            5            6       1950   \n",
       "1460          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n",
       "Id                                                      ...               \n",
       "1             2003       196.0         706           0  ...           0   \n",
       "2             1976         0.0         978           0  ...         298   \n",
       "3             2002       162.0         486           0  ...           0   \n",
       "4             1970         0.0         216           0  ...           0   \n",
       "5             2000       350.0         655           0  ...         192   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "1456          2000         0.0           0           0  ...           0   \n",
       "1457          1988       119.0         790         163  ...         349   \n",
       "1458          2006         0.0         275           0  ...           0   \n",
       "1459          1996         0.0          49        1029  ...         366   \n",
       "1460          1965         0.0         830         290  ...         736   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "Id                                                                            \n",
       "1              61              0          0            0         0        0   \n",
       "2               0              0          0            0         0        0   \n",
       "3              42              0          0            0         0        0   \n",
       "4              35            272          0            0         0        0   \n",
       "5              84              0          0            0         0        0   \n",
       "...           ...            ...        ...          ...       ...      ...   \n",
       "1456           40              0          0            0         0        0   \n",
       "1457            0              0          0            0         0        0   \n",
       "1458           60              0          0            0         0     2500   \n",
       "1459            0            112          0            0         0        0   \n",
       "1460           68              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "Id                               \n",
       "1          2    2008     208500  \n",
       "2          5    2007     181500  \n",
       "3          9    2008     223500  \n",
       "4          2    2006     140000  \n",
       "5         12    2008     250000  \n",
       "...      ...     ...        ...  \n",
       "1456       8    2007     175000  \n",
       "1457       2    2010     210000  \n",
       "1458       5    2010     266500  \n",
       "1459       4    2010     142125  \n",
       "1460       6    2008     147500  \n",
       "\n",
       "[1121 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data\n",
    "data = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv', index_col=\"Id\")\n",
    "\n",
    "# Only keep numerical columns and raws without NaN\n",
    "data = data.select_dtypes(include=np.number).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Holdout)**‚ùì\n",
    "\n",
    "üëá Split the dataset to create your `X_train` `X_test` and `y_train` `y_test`. Use:\n",
    "- `test_size=0.3`\n",
    "- `random_state=0` to compare your results with your buddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train ,y_test=train_test_split(X,y,test_size=0.3, random_state=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öñÔ∏è Scaling is always crucially important for the KNN algorithm..\n",
    "\n",
    "‚ùì **Question (Scaling)** ‚ùì \n",
    "\n",
    "* Scale your train set and test set.\n",
    "* Here, let's simply apply the `StandardScaler` and not waste time choosing one scaler per feature. Indeed, the goals of this exercise are to:\n",
    "    * review KNN\n",
    "    * understand GridSearchCV\n",
    "    * understand RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (A baseline for our KNN)** ‚ùì\n",
    "\n",
    "Cross-validate (*cv = 5*) a simple KNN regressor taking into account only _the closest neighbor_, and compute the average score over the 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5601542887874071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "cv_scores = cross_val_score(knn_regressor, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. A first GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch v1)**‚ùì\n",
    "\n",
    "Let's use SKLearn `GridSearchCV` to find the best KNN hyperparameter `n_neighbors`.\n",
    "- Start a coarse-grain approach, with `n_neighbors` = [1,5,10,20,50]\n",
    "- 5-fold cross-validate each parameter\n",
    "- Make sure to maximize your performance time using `n_jobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 5, 10, 20, 50]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 5, 10, 20, 50]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [1, 5, 10, 20, 50]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instantiate model\n",
    "knn_regressor = KNeighborsRegressor()\n",
    "# Hyperparameter Grid\n",
    "param_grid = {'n_neighbors': [1, 5, 10, 20, 50]}\n",
    "\n",
    "\n",
    "# Instantiate Grid Search\n",
    "grid_search = GridSearchCV(knn_regressor, param_grid, cv=5, n_jobs=-1)\n",
    "# Fit data to Grid Search\n",
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters)** ‚ùì\n",
    "\n",
    "According to the GridSearch, what is the optimal K value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "##### YOUR CODE HERE\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (scoring)** ‚ùì What is the best score the optimal K value produced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596697382171873"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. A second GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch V2)** ‚ùì\n",
    "\n",
    "\n",
    "Now, we have an idea about where the best $K$ lies, but some of the values we didn't try could result in a  better performance.\n",
    "\n",
    "* Re-run a GridSearch trying some values for $K$ around to your previous best value\n",
    "* What are the `best_score` and `best_k` for this refined GridSearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [5, 10, 15, 20, 25]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [5, 10, 15, 20, 25]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [5, 10, 15, 20, 25]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate model\n",
    "knn_regresso = KNeighborsRegressor()\n",
    "# Hyperparameter Grid\n",
    "param_gri = {'n_neighbors': [5, 10, 15, 20,25]}\n",
    "\n",
    "\n",
    "# Instantiate Grid Search\n",
    "grid_searc = GridSearchCV(knn_regresso, param_gri, cv=5, n_jobs=-1)\n",
    "# Fit data to Grid Search\n",
    "grid_searc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 15}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657859104933367"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score=0.7657859104933367\n",
    "best_k=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/joud/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/joud/code/joud-alharbi/data-workflow/tests\n",
      "plugins: typeguard-2.13.3, anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_knn.py::TestKnn::test_best_k \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 50%]\u001b[0m\n",
      "test_knn.py::TestKnn::test_best_score \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/knn.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed knn step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('knn',\n",
    "                         best_k=best_k,\n",
    "                         best_score=best_score)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Visual check (manual GridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This problem is actually simple enough to perform a GridSearch manually.\n",
    "\n",
    "‚ùì **Question(Manual GridSearch)** ‚ùì\n",
    "\n",
    "- Loop manually over all values of $K$ from $1$ to $50$ and store the average of the cross-validated scores of each model in a list.\n",
    "- Plot the scores as a function of $K$ to visually find the best $K$ using the `Elbow Method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cross-Validation Scores for Different K Values (KNN)')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "mean_cv_scores = []\n",
    "\n",
    "for k in range(1, 51):\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "    \n",
    "    cv_scores = cross_val_score(knn_regressor, X_train_scaled, y_train, cv=5)\n",
    "    mean_cv_scores.append(np.mean(cv_scores))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 51), mean_cv_scores, marker='o',  color='b')\n",
    "plt.title('Cross-Validation Scores for Different K Values (KNN)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìCan you guess what makes GridSearchCV a better option than such manual loop ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "- Sklearn's `n_jobs=-1` allows you to parallelize the search, utilizing all of your CPU cores\n",
    "- What if you had multiple hyper-parameters to co-optimize?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GridSearch with multiple parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ KNNRegressor suppports various _distance metrics_ via the hyper-parameter `p` \n",
    "\n",
    "üìö [sklearn.neighbors.KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "\n",
    "‚ùì **Question (tuning multiple parameters)** ‚ùì\n",
    "\n",
    "\n",
    "* Use GridSearchCV to search for the best $K$ and $p$ simultaneously.\n",
    "    * Try all combinations for $K = [1, 5, 10, 20, 50]$ and $p = [1, 2, 3]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: n_neighbors=10, p=1\n",
      "Best Cross-Validation Score: 0.7969\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "knn_regressor = KNeighborsRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 10, 20, 50],\n",
    "    'p': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(knn_regressor, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: n_neighbors={best_params['n_neighbors']}, p={best_params['p']}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (number of submodels)**‚ùì\n",
    "\n",
    "How many submodels did you train overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "Much more than 15. Think twice :)\n",
    "    <details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "75 models due to CV=5\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "a=(5*3)*5\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters and best score after tuning the model with multiple parameters)**‚ùì\n",
    "\n",
    "What are the *best parameters* and the *best score*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "best_parameters=10\n",
    "best_Score= 0.7969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see whether a RandomizedSearch can find a better combination with the same number of models being fitted.\n",
    "\n",
    "‚ùì **Question (RandomizedSearchCV)** ‚ùì\n",
    "\n",
    "Use `RandomizedSearchCV` to\n",
    "- Randomly sample $K$ from a uniform `scipy.stats.randint(1,50)` ([doc](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)) distribution\n",
    "- Sample $p$ from a list $[1,2,3]$\n",
    "- Use the correct numbers of `n_iter` and `cv` to fit the exact same numbers of models as in your previous GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (RandomizedSearchCV): n_neighbors=2, p=1\n",
      "Best Cross-Validation Score (RandomizedSearchCV): 0.7974\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "knn_regressor = KNeighborsRegressor()\n",
    "\n",
    "param_distributions = {\n",
    "    'n_neighbors': stats.randint(1, 50),\n",
    "    'p': [1, 2, 3]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    knn_regressor,\n",
    "    param_distributions,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(f\"Best parameters (RandomizedSearchCV): n_neighbors={best_params_random['n_neighbors']}, p={best_params_random['p']}\")\n",
    "print(f\"Best Cross-Validation Score (RandomizedSearchCV): {best_score_random:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (finetuning your model one more time)**‚ùì\n",
    "\n",
    "- Refine your RandomsearchCV if you want\n",
    "- Choose your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (RandomizedSearchCV): n_neighbors=8, p=1\n",
      "Best Cross-Validation Score (RandomizedSearchCV): 0.7942\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "knn_regressor = KNeighborsRegressor()\n",
    "\n",
    "param_distributions = {\n",
    "    'n_neighbors': stats.randint(1, 50),\n",
    "    'p': [1, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    knn_regressor,\n",
    "    param_distributions,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(f\"Best parameters (RandomizedSearchCV): n_neighbors={best_params_random['n_neighbors']}, p={best_params_random['p']}\")\n",
    "print(f\"Best Cross-Validation Score (RandomizedSearchCV): {best_score_random:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to display your `cv_results` as a `DataFrame`, this will help you visualize what's going on inside the CV! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 8, 'p': 1}</td>\n",
       "      <td>0.750651</td>\n",
       "      <td>0.825437</td>\n",
       "      <td>0.742715</td>\n",
       "      <td>0.866525</td>\n",
       "      <td>0.785850</td>\n",
       "      <td>0.794236</td>\n",
       "      <td>0.046527</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 1}</td>\n",
       "      <td>0.710323</td>\n",
       "      <td>0.793197</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.858920</td>\n",
       "      <td>0.847909</td>\n",
       "      <td>0.797431</td>\n",
       "      <td>0.053591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 24, 'p': 2}</td>\n",
       "      <td>0.740016</td>\n",
       "      <td>0.814477</td>\n",
       "      <td>0.695182</td>\n",
       "      <td>0.806174</td>\n",
       "      <td>0.725816</td>\n",
       "      <td>0.756333</td>\n",
       "      <td>0.046480</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 43, 'p': 2}</td>\n",
       "      <td>0.732335</td>\n",
       "      <td>0.787417</td>\n",
       "      <td>0.685419</td>\n",
       "      <td>0.763922</td>\n",
       "      <td>0.695584</td>\n",
       "      <td>0.732935</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 25, 'p': 1}</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.807158</td>\n",
       "      <td>0.723375</td>\n",
       "      <td>0.818164</td>\n",
       "      <td>0.760461</td>\n",
       "      <td>0.775792</td>\n",
       "      <td>0.034052</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 36, 'p': 2}</td>\n",
       "      <td>0.733587</td>\n",
       "      <td>0.790687</td>\n",
       "      <td>0.689146</td>\n",
       "      <td>0.779746</td>\n",
       "      <td>0.710599</td>\n",
       "      <td>0.740753</td>\n",
       "      <td>0.039084</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.190434</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 34, 'p': 3}</td>\n",
       "      <td>0.707884</td>\n",
       "      <td>0.777660</td>\n",
       "      <td>0.664898</td>\n",
       "      <td>0.752352</td>\n",
       "      <td>0.668263</td>\n",
       "      <td>0.714212</td>\n",
       "      <td>0.044863</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.199709</td>\n",
       "      <td>0.037640</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 3}</td>\n",
       "      <td>0.631907</td>\n",
       "      <td>0.700492</td>\n",
       "      <td>0.638001</td>\n",
       "      <td>0.806689</td>\n",
       "      <td>0.535899</td>\n",
       "      <td>0.662598</td>\n",
       "      <td>0.089216</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 10, 'p': 2}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.797007</td>\n",
       "      <td>0.720581</td>\n",
       "      <td>0.836532</td>\n",
       "      <td>0.715257</td>\n",
       "      <td>0.759670</td>\n",
       "      <td>0.048466</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 30, 'p': 2}</td>\n",
       "      <td>0.737478</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.697597</td>\n",
       "      <td>0.786169</td>\n",
       "      <td>0.726074</td>\n",
       "      <td>0.749629</td>\n",
       "      <td>0.038384</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.017704</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 43, 'p': 1}</td>\n",
       "      <td>0.752414</td>\n",
       "      <td>0.794293</td>\n",
       "      <td>0.712637</td>\n",
       "      <td>0.784671</td>\n",
       "      <td>0.720084</td>\n",
       "      <td>0.752820</td>\n",
       "      <td>0.032927</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.201297</td>\n",
       "      <td>0.034398</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 36, 'p': 3}</td>\n",
       "      <td>0.706706</td>\n",
       "      <td>0.776893</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>0.749579</td>\n",
       "      <td>0.663020</td>\n",
       "      <td>0.711069</td>\n",
       "      <td>0.046561</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 16, 'p': 2}</td>\n",
       "      <td>0.730270</td>\n",
       "      <td>0.814154</td>\n",
       "      <td>0.727727</td>\n",
       "      <td>0.831548</td>\n",
       "      <td>0.729457</td>\n",
       "      <td>0.766631</td>\n",
       "      <td>0.046239</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.195575</td>\n",
       "      <td>0.057839</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 30, 'p': 3}</td>\n",
       "      <td>0.709679</td>\n",
       "      <td>0.782353</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.757213</td>\n",
       "      <td>0.677139</td>\n",
       "      <td>0.721175</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 1}</td>\n",
       "      <td>0.770415</td>\n",
       "      <td>0.805646</td>\n",
       "      <td>0.720335</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.759170</td>\n",
       "      <td>0.773953</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001073      0.000212         0.005573        0.000506   \n",
       "1        0.001122      0.000256         0.004578        0.000359   \n",
       "2        0.001470      0.000230         0.003901        0.000898   \n",
       "3        0.001305      0.000181         0.003788        0.000155   \n",
       "4        0.001479      0.000340         0.007628        0.000611   \n",
       "5        0.001758      0.000371         0.004994        0.000338   \n",
       "6        0.001867      0.000274         0.190434        0.006019   \n",
       "7        0.002007      0.000497         0.199709        0.037640   \n",
       "8        0.002487      0.001563         0.004759        0.000954   \n",
       "9        0.002704      0.000678         0.007964        0.002366   \n",
       "10       0.002144      0.000296         0.017704        0.001996   \n",
       "11       0.002330      0.000893         0.201297        0.034398   \n",
       "12       0.003369      0.003119         0.007447        0.003769   \n",
       "13       0.002027      0.000266         0.195575        0.057839   \n",
       "14       0.001789      0.000180         0.013984        0.001013   \n",
       "\n",
       "   param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "0                  8       1   {'n_neighbors': 8, 'p': 1}           0.750651   \n",
       "1                  2       1   {'n_neighbors': 2, 'p': 1}           0.710323   \n",
       "2                 24       2  {'n_neighbors': 24, 'p': 2}           0.740016   \n",
       "3                 43       2  {'n_neighbors': 43, 'p': 2}           0.732335   \n",
       "4                 25       1  {'n_neighbors': 25, 'p': 1}           0.769800   \n",
       "5                 36       2  {'n_neighbors': 36, 'p': 2}           0.733587   \n",
       "6                 34       3  {'n_neighbors': 34, 'p': 3}           0.707884   \n",
       "7                  2       3   {'n_neighbors': 2, 'p': 3}           0.631907   \n",
       "8                 10       2  {'n_neighbors': 10, 'p': 2}           0.728972   \n",
       "9                 30       2  {'n_neighbors': 30, 'p': 2}           0.737478   \n",
       "10                43       1  {'n_neighbors': 43, 'p': 1}           0.752414   \n",
       "11                36       3  {'n_neighbors': 36, 'p': 3}           0.706706   \n",
       "12                16       2  {'n_neighbors': 16, 'p': 2}           0.730270   \n",
       "13                30       3  {'n_neighbors': 30, 'p': 3}           0.709679   \n",
       "14                26       1  {'n_neighbors': 26, 'p': 1}           0.770415   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.825437           0.742715           0.866525   \n",
       "1            0.793197           0.776805           0.858920   \n",
       "2            0.814477           0.695182           0.806174   \n",
       "3            0.787417           0.685419           0.763922   \n",
       "4            0.807158           0.723375           0.818164   \n",
       "5            0.790687           0.689146           0.779746   \n",
       "6            0.777660           0.664898           0.752352   \n",
       "7            0.700492           0.638001           0.806689   \n",
       "8            0.797007           0.720581           0.836532   \n",
       "9            0.800830           0.697597           0.786169   \n",
       "10           0.794293           0.712637           0.784671   \n",
       "11           0.776893           0.659146           0.749579   \n",
       "12           0.814154           0.727727           0.831548   \n",
       "13           0.782353           0.679488           0.757213   \n",
       "14           0.805646           0.720335           0.814200   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.785850         0.794236        0.046527                2  \n",
       "1            0.847909         0.797431        0.053591                1  \n",
       "2            0.725816         0.756333        0.046480                7  \n",
       "3            0.695584         0.732935        0.038940               11  \n",
       "4            0.760461         0.775792        0.034052                3  \n",
       "5            0.710599         0.740753        0.039084               10  \n",
       "6            0.668263         0.714212        0.044863               13  \n",
       "7            0.535899         0.662598        0.089216               15  \n",
       "8            0.715257         0.759670        0.048466                6  \n",
       "9            0.726074         0.749629        0.038384                9  \n",
       "10           0.720084         0.752820        0.032927                8  \n",
       "11           0.663020         0.711069        0.046561               14  \n",
       "12           0.729457         0.766631        0.046239                5  \n",
       "13           0.677139         0.721175        0.042073               12  \n",
       "14           0.759170         0.773953        0.033853                4  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "cv_results_df = pd.DataFrame(random_search.cv_results_)\n",
    "cv_results_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Evaluation of the \"best\" model)** ‚ùì\n",
    "\n",
    "* Time has come to discover our model's performance with \"best params\" on the **unseen** test set `X_test`.\n",
    "    * Compute the r2 score for the test set and save it as `r2_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score on Test Set: 0.7457\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Instantiate the KNN regressor with the best parameters found\n",
    "best_knn_regressor = KNeighborsRegressor(\n",
    "    n_neighbors=random_search.best_params_['n_neighbors'],\n",
    "    p=random_search.best_params_['p']\n",
    ")\n",
    "\n",
    "# Train the final model on the scaled training data\n",
    "best_knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the scaled test set\n",
    "y_test_pred = best_knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Compute the R^2 score for the test set\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R^2 Score on Test Set: {r2_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Taking a step back)** ‚ùì\n",
    "\n",
    "Would you consider the optimized model to generalize well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer</summary>\n",
    "\n",
    "Test score may decrease a bit with train set. Probably not more than 5%. This can be due to\n",
    "- A non-representative train/test split\n",
    "- A cross-val number too small leading to overfitting the model-tuning phase. The more you cross-validated, the more robust your findings will generalize - but you can't increase cv too much if your dataset is too small as you won't keep enough observations in each fold to be representative.\n",
    "- Our dataset is very small and our hyperparameter optimization is thus extremely dependent (and overfitting) on our train/test split. Always make sure your dataset is much bigger than the total number of hyperparameter combinations you are trying out!\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/joud/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/joud/code/joud-alharbi/data-workflow/tests\n",
      "plugins: typeguard-2.13.3, anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_r2.py::TestR2::test_r2 \u001b[32mPASSED\u001b[0m\u001b[32m                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.16s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/r2.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed r2 step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('r2', \n",
    "                         r2_test=r2_test)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to finetune a model using either a GridSearchCV or a RandomizedSearchCV \n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
